{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import timm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kaggle/input/auto-dataset/techosmotr/techosmotr/train\"   \n",
    "\n",
    "config = {\n",
    "    \"epoch\": 5,\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 1e-3,\n",
    "    \"momentum\": 0.9,\n",
    "    \"decay\": 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model on ImageNet-1000 dataset that is used as a backbone\n",
    "efficient_net = \"efficientnet_b0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoDataset(Dataset):\n",
    "    def __init__(self, dir: str, transform):\n",
    "        self.data = ImageFolder(dir, transform=transform)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes: int=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.base_model = timm.create_model(efficient_net, pretrained=True)\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=1280, out_features=num_classes),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and Standard deviation were calculated separately using training_set data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Normalize(mean=[0.0256, 0.0259, 0.0263], std=[0.0158, 0.0157, 0.0158])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AutoDataset(dir=path, transform=transform, ela=True)\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [5927, 329, 329])\n",
    "train_loader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=config[\"batch_size\"])\n",
    "test_loader = DataLoader(test_set, batch_size=config[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "\n",
    "optimizer = optim.SGD(params=model.parameters(), \n",
    "                      lr=config[\"lr\"], \n",
    "                      momentum=config[\"momentum\"],\n",
    "                      weight_decay=config[\"decay\"])\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in (range(config[\"epoch\"])):\n",
    "    model.train()\n",
    "    print(\"Training started...\")\n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in (train_loader):\n",
    "        images, labels = images.to(device), labels.to(device).to(torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze(1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device).to(torch.float32)\n",
    "\n",
    "            outputs = model(images).squeeze(1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "        val_loss = running_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Train loss: {train_loss}, Val loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img, label):\n",
    "    model.eval()\n",
    "    output = model(img.to(device).unsqueeze(0)).squeeze(1)\n",
    "    return label, 1 if output>0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in test_set:\n",
    "    label, output = predict(*i)\n",
    "    y_true.append(label)\n",
    "    y_pred.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/kaggle/input/auto-dataset/test.csv\")\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(columns=['file_index', 'class'])\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    index = row.iloc[0]\n",
    "    \n",
    "    path = f'/kaggle/input/auto-dataset/techosmotr/techosmotr/test/{index}.jpeg'\n",
    "    # print(path)\n",
    "    img = Image.open(path)\n",
    "    img = transform(img)\n",
    "    output = model(img.to(device).unsqueeze(0)).squeeze(1)\n",
    "    output = 1 if output>0.5 else 0\n",
    "    \n",
    "    pred_df.loc[len(pred_df.index)] = [index, 1-output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
