{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import timm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kaggle/input/auto-dataset/techosmotr/techosmotr/train\"   \n",
    "\n",
    "config = {\n",
    "    \"epoch\": 5,\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 1e-3,\n",
    "    \"momentum\": 0.9,\n",
    "    \"decay\": 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model on ImageNet-1000 dataset that is used as a backbone\n",
    "# We have used efficient net because it is one of the best classification models\n",
    "# b0 model is the smallest one, which means it is less accurate but much faster\n",
    "# Using pretrained model saves up a lot of time because we do not need to train model\n",
    "# for long time to adjust weights\n",
    "efficient_net = \"efficientnet_b0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoDataset(Dataset):\n",
    "    def __init__(self, dir: str, transform):\n",
    "        self.data = ImageFolder(dir, transform=transform)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Our model uses given pretrained model and applies linear layer to the\n",
    "    results of the second last layer of the pretrained model because\n",
    "    EfficientNet was trained on 1000 classes\n",
    "    This model can be used also on multilabel tasks just by setting\n",
    "    num_classes variables to number of classes\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.base_model = timm.create_model(efficient_net, pretrained=True)\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=1280, out_features=num_classes),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and Standard deviation were calculated separately using training_set data\n",
    "# We have decided to not use rotations and other such transformations\n",
    "# because our interest targets, cars, are located horizontally in each image\n",
    "# and rotating and flipping them might confuse the model\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Normalize(mean=[0.0256, 0.0259, 0.0263], std=[0.0158, 0.0157, 0.0158])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset was divided into trainset(90%), valset(5%), testset(5%)\n",
    "dataset = AutoDataset(dir=path, transform=transform, ela=True)\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [5927, 329, 329])\n",
    "train_loader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=config[\"batch_size\"])\n",
    "test_loader = DataLoader(test_set, batch_size=config[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of mean and std from the training set\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "for images, _ in train_loader:\n",
    "    # Calculate mean and std for each channel separately\n",
    "    mean += torch.mean(images, dim=(0, 2, 3))\n",
    "    std += torch.std(images, dim=(0, 2, 3))\n",
    "\n",
    "mean /= len(dataset)\n",
    "std /= len(dataset)\n",
    "\n",
    "print(\"Mean per channel:\", mean)\n",
    "print(\"Std per channel:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "\n",
    "optimizer = optim.SGD(params=model.parameters(), \n",
    "                      lr=config[\"lr\"], \n",
    "                      momentum=config[\"momentum\"],\n",
    "                      weight_decay=config[\"decay\"])\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have experimented with several model parameters, including\n",
    "# different loss function and number of epochs\n",
    "# By that, we have found that number of epochs larger than 10 for\n",
    "# default SGD optimizer overfits the model and it would generalize\n",
    "# very poor to unseen data\n",
    "# Whereas number of epochs larger than 5-6 also overfits the model\n",
    "# for SGD optimizer with momentum and weight decay parameters\n",
    "\n",
    "# We also have experimented with Softmax instead of Sigmoid\n",
    "# and found that Softmax performs poorer\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in (range(config[\"epoch\"])):\n",
    "    model.train()\n",
    "    print(\"Training started...\")\n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in (train_loader):\n",
    "        images, labels = images.to(device), labels.to(device).to(torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze(1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device).to(torch.float32)\n",
    "\n",
    "            outputs = model(images).squeeze(1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "        val_loss = running_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Train loss: {train_loss}, Val loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img, label):\n",
    "    model.eval()\n",
    "    output = model(img.to(device).unsqueeze(0)).squeeze(1)\n",
    "    return label, 1 if output>0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in test_set:\n",
    "    label, output = predict(*i)\n",
    "    y_true.append(label)\n",
    "    y_pred.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/kaggle/input/auto-dataset/test.csv\")\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason we are subtracting output from 1\n",
    "# is because ImageFolder class used in Dataset\n",
    "# automatically set 1 for true car images and\n",
    "# 0 for fake car images\n",
    "\n",
    "pred_df = pd.DataFrame(columns=['file_index', 'class'])\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    index = row.iloc[0]\n",
    "    \n",
    "    path = f'/kaggle/input/auto-dataset/techosmotr/techosmotr/test/{index}.jpeg'\n",
    "    # print(path)\n",
    "    img = Image.open(path)\n",
    "    img = transform(img)\n",
    "    output = model(img.to(device).unsqueeze(0)).squeeze(1)\n",
    "    output = 1 if output>0.5 else 0\n",
    "    \n",
    "    pred_df.loc[len(pred_df.index)] = [index, 1-output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
